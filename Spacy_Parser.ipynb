{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of sysntatic parser using spacy\n",
    "\n",
    "# install\n",
    "pip install spacy\n",
    "python -m spacy.en.download all\n",
    "\n",
    "\n",
    "# docs\n",
    "https://spacy.io\n",
    "\n",
    "http://www.mathcs.emory.edu/~choi/doc/clear-dependency-2012.pdf\n",
    "\n",
    "http://aclweb.org/anthology/P/P15/P15-1038.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'types' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a4c48afea4dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0moldmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mreload_package\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-a4c48afea4dd>\u001b[0m in \u001b[0;36mreload_package\u001b[1;34m(root_module)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# get a reference to each loaded module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     loaded_package_modules = dict([\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         if key.startswith(package_name) and isinstance(value, types.ModuleType)])\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-a4c48afea4dd>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     12\u001b[0m     loaded_package_modules = dict([\n\u001b[0;32m     13\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         if key.startswith(package_name) and isinstance(value, types.ModuleType)])\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# delete references to these loaded modules from sys.modules\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'types' is not defined"
     ]
    }
   ],
   "source": [
    "#starting spacy\n",
    "from spacy.en import English\n",
    "nlp = English()\n",
    "from __future__ import unicode_literals     \n",
    "import resource\n",
    "import sys\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['If not Your first step is to choose an agent.\\n', 'Your agent will receive communication from the NVC about your case.\\n', 'You may have an agent that represented you and the petitioner in the petition process with USCIS. \\n', 'However, you will need to formally select an agent to represent you for your visa processing.\\n', 'To choose your agent, complete the Choice of Address and Agent (DS261) form in the Consular Electronic Application Center.']\n"
     ]
    }
   ],
   "source": [
    "#opening sentences file\n",
    "f = open('sentences.txt', 'r')\n",
    "sentences = f.readlines()\n",
    "\n",
    "print(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You may have an agent that represented you and the petitioner in the petition process with USCIS \n",
      "You  <- have  (nsubj)\n",
      "may  <- have  (aux)\n",
      "have  <- have  (ROOT)\n",
      "abaixo o verbo\n",
      "have \n",
      "tag->VB\n",
      "passo aqui 1\n",
      "tag->VB\n",
      "an  <- agent  (det)\n",
      "agent  <- have  (dobj)\n",
      "that  <- represented  (nsubj)\n",
      "represented  <- agent  (relcl)\n",
      "you  <- represented  (dobj)\n",
      "and  <- you  (cc)\n",
      "the  <- petitioner  (det)\n",
      "petitioner  <- you  (conj)\n",
      "in  <- represented  (prep)\n",
      "the  <- process  (det)\n",
      "petition  <- process  (compound)\n",
      "process  <- in  (pobj)\n",
      "with  <- represented  (prep)\n",
      "USCIS <- with  (pobj)\n"
     ]
    }
   ],
   "source": [
    "sentenca = sentences[2].replace(\".\",\"\").replace(\"\\n\",\"\")\n",
    "print (sentenca)\n",
    "\n",
    "doc = nlp(str(sentenca))\n",
    "for word in doc:\n",
    "    #print (\"teste= \"+ word.pos_)\n",
    "    print(word.text_with_ws + \" <- \"  + word.head.text_with_ws + \" (\"  + word.dep_ + \")\" )\n",
    "    \n",
    "    if (word.text_with_ws in (word.head.text_with_ws) and  word.dep_ in ('ROOT')):\n",
    "        print (\"abaixo o verbo\")\n",
    "        print (word.text_with_ws)\n",
    "        print(\"tag->\" + word.tag_)\n",
    "        \n",
    "        if (word.tag_ == \"VBP\" or word.tag_ == \"VBZ\" or word.tag_ == \"VB\"):\n",
    "            print (\"passo aqui 1\")\n",
    "            print(\"tag->\" + word.tag_)\n",
    "            #return TIPO_SENTENCA_Activity\n",
    "        elif (word.tag_ == \"VBD\" or word.tag_ == \"VBN\" ):\n",
    "             print (\"passo aqui 1\")\n",
    "            #print(\"tag->\" + word.tag_)\n",
    "            #return TIPO_SENTENCA_Event\n",
    "    #if (word.head):\n",
    "    #    print (\" pai: \"+ word.head.text_with_ws)\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n",
      "Sentenca: If not Your first step is to choose an agent\n",
      "If\n",
      "passo por aqui 1\n",
      "passo por aqui 2\n",
      "passo por aqui 3\n",
      "tipo da sentenca\n",
      "1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Go_Rule_XOR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-591ffb6585eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype_of_sentence\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mTIPO_SENTENCA_XOR\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mGo_Rule_XOR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtype_of_sentence\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mTIPO_SENTENCA_AND\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mGo_Rule_AND\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Go_Rule_XOR' is not defined"
     ]
    }
   ],
   "source": [
    "#imprimindo \n",
    "\n",
    "        \n",
    "for sent in sentences:\n",
    "        sent = sent.replace(\".\",\"\").replace(\"\\n\",\"\")\n",
    "        print (\"--\")\n",
    "        print (\"Sentenca: \"+ sent)\n",
    "        doc = nlp(str(sent))\n",
    "        cont1=0\n",
    "        TIPO_SENTENCA_XOR = 1\n",
    "        TIPO_SENTENCA_AND = 2    \n",
    "        TIPO_SENTENCA_OTHERS = 3\n",
    "        TIPO_SENTENCA_Activity = 4\n",
    "        TIPO_SENTENCA_Event = 5\n",
    "\n",
    "\n",
    "        type_of_sentence = get_type_senteces(doc)\n",
    "\n",
    "\n",
    "        print(\"tipo da sentenca abaixo\")\n",
    "        print(type_of_sentence)    \n",
    "\n",
    "        if type_of_sentence == TIPO_SENTENCA_XOR:\n",
    "            Go_Rule_XOR(doc)\n",
    "        elif type_of_sentence == TIPO_SENTENCA_AND:\n",
    "            Go_Rule_AND(doc)\n",
    "        else:\n",
    "            Go_Rules_Activity_Event(doc)\n",
    "            \n",
    "        #print(\"tipo: \"+ s.get_type_senteces.text_with_ws)\n",
    "\n",
    "        #if (regra1(doc)):\n",
    "            #cont1=cont1+1 \n",
    "            #print (\"sentenca:\"+ sent)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_type_senteces(doc):\n",
    "    for idx, val in enumerate (doc):          \n",
    "        if isSIGNAL_WORDS_XOR(idx,val,doc):\n",
    "            return TIPO_SENTENCA_XOR\n",
    "    for idx, val in enumerate (doc):          \n",
    "        if isSIGNAL_WORDS_AND(idx,val,doc):\n",
    "            return TIPO_SENTENCA_AND\n",
    "    return TIPO_SENTENCA_OTHERS    \n",
    "     \n",
    "\n",
    "def isSIGNAL_WORDS_XOR(idx,val,doc):\n",
    "    print (val)\n",
    "    print(\"passo por aqui 1\")\n",
    "    if \"if\" in str(val).lower():\n",
    "        print(\"passo por aqui 2\")\n",
    "        z=doc[idx+1]       \n",
    "        if \"not\" in str(z).lower(): \n",
    "            print(\"passo por aqui 3\")\n",
    "\n",
    "            return True\n",
    "    elif \"if\" in str(val).lower()  or \"otherwise\"  in str(val).lower() or \"either\"  in str(val).lower() or  \"only\"  in str(val).lower() or \"till\"  in str(val).lower() or \"until\"  in str(val).lower() or \"when\"  in str(val).lower():\n",
    "        print(\"passo por aqui 4\")\n",
    "        return True\n",
    "    \n",
    "    elif \"in\"  in str(val).lower():\n",
    "        print(\"passo por aqui 5\")\n",
    "        z=doc[idx+1]\n",
    "        y=doc[idx+2]\n",
    "        if \"case\"  in str(z).lower() or (\"case\"  in str(z).lower() and \"of\"  in str(y).lower()):\n",
    "            print(\"passo por aqui 6\")\n",
    "            return True\n",
    "    else:\n",
    "        print(\"passo por aqui 7\")\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def isSIGNAL_WORDS_AND(idx,val,doc):\n",
    "    print (val)\n",
    "    print(\"passo por aqui 8\")\n",
    "    if \"while\"  in str(val).lower()  or \"meanwhile\" in str(val).lower() or \"concurrently\" in str(val).lower() or \"meantime\" in str(val).lower() or \"simultaneously\" in str(val).lower() or \"whereas\"  in str(val).lower():\n",
    "        print(\"passo por aqui 9\")\n",
    "        return True\n",
    "    elif \"In\"  in str(val).lower():\n",
    "        print(\"passo por aqui 10\")\n",
    "        z=doc[idx+1]\n",
    "        y=doc[idx+2]\n",
    "        q=doc[idx+3]\n",
    "        if (\"parallel\"  in str(z).lower() or (\"parallel\"  in str(z).lower() and \"with\"  in str(y).lower() and \"this\" in str(q).lower())):\n",
    "            print(\"passo por aqui 11\")\n",
    "            return True\n",
    "        elif (\"the\"  in str(z).lower() and \"meantime\" in str(y).lower()):\n",
    "            print(\"passo por aqui 12\")\n",
    "            return True\n",
    "        elif (\"addition\"  in str(z).lower() and \"to\"  in str(y).lower()):\n",
    "            print(\"passo por aqui 13\")\n",
    "            return True\n",
    "    elif \"at\"  in str(val).lower():\n",
    "        z=doc[idx+1]\n",
    "        y=doc[idx+2]\n",
    "        q=doc[idx+3]\n",
    "        print(\"passo por aqui 14\")\n",
    "        if (\"the\"  in str(z).lower() and \"same\" in str(y).lower() and \"time\" in str(q).lower()):\n",
    "            print(\"passo por aqui 15\")\n",
    "            return True           \n",
    "    else:\n",
    "        print(\"passo por aqui 16\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "## CHAMADAS DAS REGRAS\n",
    "def Go_Rules_Activity_Event(doc):\n",
    "\tMain_Verb = Definition_Main_Verb_Activity_or_Event (doc)\n",
    "\tResult_Verb_Tense = Definition_Verb_tense_Main_Verb(Main_Verb) \n",
    "\tif (Result_Verb_Tense == TIPO_SENTENCA_Activity):\n",
    "\t\tGo_Rules_Activity (doc)\n",
    "\telse:\n",
    "\t\tGo_Rules_Event (doc)\n",
    "\t#PAREI AQUI\n",
    "\n",
    "\n",
    "        \n",
    "def Definition_Main_Verb_Activity_or_Event (doc):\n",
    "   \n",
    "\tfor word in doc:\n",
    "\t\t#print (\"teste= \"+ word.pos_)\n",
    "\t\tprint(word.text_with_ws + \" <- \"  + word.head.text_with_ws + \" (\"  + word.dep_ + \")\" )\n",
    "\t\t\t#Aqui eu comparo se a palavra é ela mesma e se ela é \"root\" ou seja, o verbo principal da sentenca\n",
    "\t\tif (word.text_with_ws in (word.head.text_with_ws) and  word.dep_ in ('ROOT')):\n",
    "\t\t\tMain_Verb1=word\n",
    "\t\t\treturn Main_Verb1\n",
    "\n",
    "def Definition_Verb_tense_Main_Verb (Main_Verb):\n",
    "\t# aqui eu vejo qual tempo verbal é o verbo principal \n",
    "\n",
    "\t#VB Verb, base form\n",
    "\t# VBD Verb, past tense\n",
    "\t#VBG Verb, gerund or present participle\n",
    "\t#VBN Verb, past participle\n",
    "\t#VBP Verb, non-3rd person singular present\n",
    "\t# VBZ Verb, 3rd person singular present\n",
    "\t    \n",
    "\tif (Main_Verb.tag_ == \"VBP\" or Main_Verb.tag_ == \"VBZ\" or Main_Verb.tag_ == \"VB\"):\n",
    "\t\treturn TIPO_SENTENCA_Activity\n",
    "\telif (Main_Verb.tag_ == \"VBD\" or Main_Verb.tag_ == \"VBN\" ):\n",
    "\t\treturn TIPO_SENTENCA_Event\n",
    "\n",
    "\n",
    "def regra1(doc):\n",
    "\tcont1=0\n",
    "\n",
    "\tfor word in doc:\n",
    "\t\t#print (''+dependency_labels_to_root(word)[0])\n",
    "\t\t#print word.text_with_ws \n",
    "\t\t#print  dependency_labels_to_root(word)\n",
    "\t\t#print word.text_with_ws + ' '+word.tag_\n",
    "\t\tif word.dep_ in ('nsubj' , 'csubj'):\n",
    "\t\t\tsujeito = ''.join(w.text_with_ws for w in word.subtree)\n",
    "\t\t\tprint ('sujeito: ' + sujeito)\n",
    "\n",
    "\n",
    "\t\t#if word.tag_ in ('VBZ'):\n",
    "\t\t#    print ('verb:' + word.text_with_ws)\n",
    "\t\t#   print(''.join(w.text_with_ws for w in word.subtree))\n",
    "\n",
    "\n",
    "\t\tif word.dep_ in ('dobj', 'iobj'):\n",
    "\t\t\tobj=''.join(w.text_with_ws for w in word.subtree)\n",
    "\t\t\t#print (word.subtree[0].text_with_ws)\n",
    "\t\t\tprint('objeto: ' + obj)\n",
    "\t\t\tfor w in word.subtree:\n",
    "\t\t\t\tif w.dep_ in ('dobj', 'iobj'):\n",
    "\t\t\t\t\tprint (\"verbo: \" + word.head.text_with_ws)\n",
    "\t\t\t\t\tprint (\"-->\" + w.text_with_ws)\n",
    "\n",
    "\t\t\t#achar_verbo_arvore(word.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
